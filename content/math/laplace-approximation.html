
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Laplace Approximation &#8212; Disorder Transform</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="2. Computing Hessian and Jacobian" href="computing-hessian-and-jacobian.html" />
    <link rel="prev" title="7. Method of kernels" href="method-of-kernels.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Disorder Transform</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   This is mostly for fun
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Math
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   1. Theoretical minimum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="probability-distributions.html">
   2. Distribuições de probabilidade
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="information-theory.html">
   3. Entropia e informação mútua
   <a class="anchor" id="3">
   </a>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="simple-example-of-maximum-likelihood.html">
   4. Simple example of maximum likelihood
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="eigen-decomposition.html">
   5. Decomposição de matrizes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lagrange-multipliers.html">
   6. Multiplicadores de Lagrange
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="method-of-kernels.html">
   7. Method of kernels
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Laplace Approximation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="computing-hessian-and-jacobian.html">
   2. Computing Hessian and Jacobian
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="counter-factual-model.html">
   3. Counter Factual Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="intro-manifold.html">
   5. Introdução ao Manifold Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multidimensional-scaling.html">
   6. Manifold Learning - Multidimensional Scaling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="variational-autoencoder.html">
   7. Variational AutoEncoder
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reinforcement Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../reinforcement-learning/intro.html">
   1. Beyond conventional machine learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reinforcement-learning/other/k-armed-bandits.html">
   2. The Multi-Armed Bandits: Exploitation vs Exploration
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Differential Geometry
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../differential-geometry/intro.html">
   1. Problems and solutions in differential geometry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../differential-geometry/maps.html">
   2. Mapas, Curvas, superfícies e Variedades
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../differential-geometry/vector-spaces.html">
   3. Espaços Vetoriais
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../differential-geometry/algebras.html">
   4. Álgebras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../differential-geometry/metric-tensor-fields.html">
   5. Campos Tensoriais Métricos
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Extra content
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../extra/definitions.html">
   Definições
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extra/symbol-index.html">
   Lista de símbolos
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/math/laplace-approximation.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/onimaru/source"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/onimaru/source/issues/new?title=Issue%20on%20page%20%2Fcontent/math/laplace-approximation.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-do-we-need-that">
   1.1. Why do we need that?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#developing-laplace-approximation">
   1.2. Developing Laplace Approximation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-use-it">
   1.3. How to use it
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="laplace-approximation">
<h1><span class="section-number">1. </span>Laplace Approximation<a class="headerlink" href="#laplace-approximation" title="Permalink to this headline">¶</a></h1>
<p>This is a framework to find an Gaussian approximation to a probability density. Since it is Gaussian it is defined over continuous variables.</p>
<p><strong>Summary</strong>: it is actually really simple. We need to find de <code class="docutils literal notranslate"><span class="pre">mode</span></code> of a probability density and create a Gaussian density distribution centered at this point. We will also need to find the curvature, or the precision, in the same point.</p>
<div class="section" id="why-do-we-need-that">
<h2><span class="section-number">1.1. </span>Why do we need that?<a class="headerlink" href="#why-do-we-need-that" title="Permalink to this headline">¶</a></h2>
<p>Most of the time we are dealing with complicated probability distributions for which, for example, we do not have an easy way to sample or compute expectations. In cases like that may be worth it to use an approximation with an easy to handle probability distribution.</p>
<p>We can go beyond that. As we will see, La place Approximation can be used to transform a common neural network in a bayesian neural network. This will give us expectation and uncertainty.</p>
</div>
<div class="section" id="developing-laplace-approximation">
<h2><span class="section-number">1.2. </span>Developing Laplace Approximation<a class="headerlink" href="#developing-laplace-approximation" title="Permalink to this headline">¶</a></h2>
<p>Suppose we have an unknown probability distribution over a one dimensional random variable <span class="math notranslate nohighlight">\(z\)</span>:</p>
<div class="math notranslate nohighlight">
\[p(z) = \frac{f(z)}{Z}\]</div>
<p>where <span class="math notranslate nohighlight">\(Z = \int f(z)dz\)</span>. We want to find and Gaussian approximation <span class="math notranslate nohighlight">\(q(z)\)</span> centered at the mode of <span class="math notranslate nohighlight">\(p(z)\)</span>. The mode is the point <span class="math notranslate nohighlight">\(z_{0}\)</span> in which <span class="math notranslate nohighlight">\(\frac{df}{dz}\vert_{z=z_{0}}\)</span>, it is independent of the normalization factor <span class="math notranslate nohighlight">\(Z\)</span>.</p>
<p>Since we are making an approximation let us expand <span class="math notranslate nohighlight">\(f(z)\)</span> or <span class="math notranslate nohighlight">\(\ln{f(z)}\)</span> around <span class="math notranslate nohighlight">\(z_{0}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\ln{f(z)} = \sum_{n=0}^{\infty}\frac{(\ln{f(z)})^{(n)}}{n!}\vert_{z=z_{0}}(z-z_{0})^{n}\]</div>
<p>Expanding it until second order we have:</p>
<div class="math notranslate nohighlight">
\[\ln{f(z)} \approx \left.\ln{f(z)}\right|_{z=z_{0}} + \left.\frac{1}{f(z)}\frac{df(z)}{dz}\right|_{z=z_{0}}(z-z_{0}) + \left.\left(\frac{-1}{f(z)^{2}} \left(\frac{df(z)}{dz} \right)^{2} + \frac{1}{f(z)} \frac{d^{2}f(z)}{dz^{2}} \right) \right|_{z=z_{0}} \frac{(z-z_{0})^{2}}{2!}\]</div>
<p>We know that <span class="math notranslate nohighlight">\(\frac{df}{dz}\vert_{z=z_{0}}\)</span>, which simplifies the equation</p>
<div class="math notranslate nohighlight">
\[\ln{f(z)} \approx \ln{f(z_{0})} + \left.\frac{d^{2}}{dz}\ln{f(z)}\right|_{z=z_{0}} \frac{(z-z_{0})^{2}}{2!}\]</div>
<p>Now we exponentiate everything to get</p>
<div class="math notranslate nohighlight">
\[f(z) \approx f(z_{0}) e^{\left(\frac{-A}{2} (z-z_{0})^{2} \right)}\]</div>
<p>where <span class="math notranslate nohighlight">\(A = \left.\frac{d^{2}}{dz}\ln{f(z)}\right|_{z=z_{0}}\)</span>. Note that we used</p>
<div class="math notranslate nohighlight">
\[\frac{d^{2}}{dz}\ln{f(z)} = \left(\frac{-1}{f(z)^{2}} \left(\frac{df(z)}{dz} \right)^{2} + \frac{1}{f(z)} \frac{d^{2}f(z)}{dz^{2}} \right).\]</div>
<p>Comparing the result with the Gaussian distribution one can see that <span class="math notranslate nohighlight">\(f(z_{0}) = \sqrt{\frac{A}{2 \pi}}\)</span> and <span class="math notranslate nohighlight">\(A &gt; 0\)</span>. We conclude that <span class="math notranslate nohighlight">\(A\)</span> is the precision <span class="math notranslate nohighlight">\(A = \frac{1}{\sigma^{2}}\)</span>.</p>
<p>So <span class="math notranslate nohighlight">\(A\)</span> is the curvature of a Gaussian at <span class="math notranslate nohighlight">\(z_{0}\)</span>. If the curvature goes to infinity, the standard deviation goes to zero, resulting in the Dirac distribution.</p>
<p>It will be more clear if we extend this to a multidimensional random variable, where <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> is the random variable vector and our constraint is <span class="math notranslate nohighlight">\(\nabla f(\mathbf{z})=0\)</span> at point <span class="math notranslate nohighlight">\(\mathbf{z}_{0}\)</span>. The final equation is almost the same, but now we have a quadratic form:</p>
<div class="math notranslate nohighlight">
\[\ln{f(z)} \approx \ln{f(z_{0})} - \frac{1}{2}(\mathbf{z}-\mathbf{z}_{0})^{\top}A (\mathbf{z}-\mathbf{z}_{0})\]</div>
<p>Since <span class="math notranslate nohighlight">\(f\)</span> receives a multidimensional vector and returns a number (a scalar field), its gradient is a vector field and when we compute the second derivative (the Jacobian of the gradient) we are actually computing the Hessian matrix. In conclusion, <span class="math notranslate nohighlight">\(A\)</span> is the Hessian matrix at point <span class="math notranslate nohighlight">\(\mathbf{z}_{0}\)</span>, the curvature matrix.</p>
<p>Finally, our approximation is</p>
<div class="math notranslate nohighlight">
\[q(\mathbf{z}) = \frac{\left| A \right|^{\frac{1}{2}}}{\left(2 \pi \right)^{\frac{n}{2}}} exp \left( - \frac{1}{2}(\mathbf{z}-\mathbf{z}_{0})^{\top}A (\mathbf{z}-\mathbf{z}_{0})\right) = \mathcal{N}(\mathbf{z} | \mathbf{z}_{0}, A^{-1}),\]</div>
<p>where <span class="math notranslate nohighlight">\(\left| A \right|\)</span> is the determinant of <span class="math notranslate nohighlight">\(A\)</span>.</p>
</div>
<div class="section" id="how-to-use-it">
<h2><span class="section-number">1.3. </span>How to use it<a class="headerlink" href="#how-to-use-it" title="Permalink to this headline">¶</a></h2>
<p>We know an expression for <span class="math notranslate nohighlight">\(q(\mathbf{z})\)</span>. To apply the Laplace Approximation we just need to find de mode <span class="math notranslate nohighlight">\(\mathbf{z}_{0}\)</span> with any numeric optimization algorithm and then use some algorithm tocompute the Hessian at this point.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/math"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="method-of-kernels.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">7. </span>Method of kernels</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="computing-hessian-and-jacobian.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Computing Hessian and Jacobian</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By onimaru<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>